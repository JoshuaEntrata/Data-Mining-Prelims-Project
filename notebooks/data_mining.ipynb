{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š **Data Mining Preliminary Project**\n",
    "\n",
    "**Group Members:**\n",
    "- Nathanael Chris Abrigo\n",
    "- Dwight Kenneth Cruz\n",
    "- Joshua Kyle Kessel Entrata\n",
    "- Edjin Jerney Payumo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install the required packages \n",
    "# Uncomment the following line to install the required packages\n",
    "\n",
    "# !pip install pandas numpy seaborn matplotlib plotly scikit-learn nbformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "### Importing Libraries\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the 2023 FIES Dataset Volume 2\n",
    "fies_23 = pd.read_csv('../data/raw/FIES PUF 2023 Volume2 Household Summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the first 10 rows of the dataset\n",
    "pd.set_option('display.max_columns', None)\n",
    "fies_23.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the shape of the dataset\n",
    "fies_23.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the columns of the dataset\n",
    "fies_23.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the data types of the columns and the number of non-null values\n",
    "fies_23.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the summary statistics of the dataset\n",
    "fies_23.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Displaying the missing values in the dataset\n",
    "\n",
    "# Calculating the Missing Values % contribution in DF\n",
    "df_null = round(100*(fies_23.isnull().sum())/len(fies_23), 2)\n",
    "\n",
    "# Plotting the df_null\n",
    "plt.figure(figsize=(16,8))\n",
    "sns.barplot(x=df_null.index, y=df_null.values, alpha=0.8)\n",
    "plt.title('Missing Values (Pre-Cleaning)')\n",
    "plt.ylabel('Missing Values %')\n",
    "plt.xlabel('Columns')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying duplicate rows using `duplicated()` method\n",
    "duplicate_rows = fies_23[fies_23.duplicated()]\n",
    "print(f\"Number of duplicate rows: {duplicate_rows.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying duplicate rows by comparing total rows with unique rows\n",
    "total_rows = fies_23.shape[0]\n",
    "unique_rows = fies_23.drop_duplicates().shape[0]\n",
    "duplicate_rows = total_rows - unique_rows\n",
    "\n",
    "print(f\"Total rows: {total_rows}\")\n",
    "print(f\"Unique rows: {unique_rows}\")\n",
    "print(f\"Duplicate rows: {duplicate_rows}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_fies = fies_23.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_aggregation(\n",
    "    dataframe, components, aggregated_column, negative_components=None, temp_column_name=\"TEMP_SUM\", tolerance=0.0\n",
    "):\n",
    "    # Validate input columns\n",
    "    all_columns = components + (negative_components if negative_components else []) + [aggregated_column]\n",
    "    missing_columns = [col for col in all_columns if col not in dataframe.columns]\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing columns in the DataFrame: {missing_columns}\")\n",
    "\n",
    "    temp_df = dataframe.copy()\n",
    "\n",
    "    # Convert relevant columns to float64 to ensure consistency\n",
    "    temp_df[aggregated_column] = temp_df[aggregated_column].astype(np.float64)\n",
    "    \n",
    "    # Calculate the sum of positive components\n",
    "    temp_df[temp_column_name] = temp_df[components].sum(axis=1)\n",
    "\n",
    "    # Subtract negative components if provided\n",
    "    if negative_components:\n",
    "        temp_df[temp_column_name] -= temp_df[negative_components].sum(axis=1)\n",
    "\n",
    "    # Use np.isclose to check if values are within the tolerance\n",
    "    temp_df['MATCH'] = np.isclose(temp_df[aggregated_column], temp_df[temp_column_name], atol=tolerance)\n",
    "\n",
    "    # Identify mismatched rows\n",
    "    mismatched_rows = temp_df[~temp_df['MATCH']][[aggregated_column, temp_column_name]]\n",
    "\n",
    "    # Output results\n",
    "    if mismatched_rows.empty:\n",
    "        result = f\"The '{aggregated_column}' column is correctly aggregated from its components within a tolerance of Â±{tolerance}.\"\n",
    "    else:\n",
    "        result = f\"Number of mismatched rows: {len(mismatched_rows)}\"\n",
    "\n",
    "    return mismatched_rows, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible component columns\n",
    "components = [\n",
    "    'REG_SAL', 'SEASON_SAL'\n",
    "]\n",
    "\n",
    "loss_components = []\n",
    "aggregate_column = 'WAGES'\n",
    "\n",
    "# Call the function verify the aggregated column\n",
    "mismatched_rows, result = check_aggregation(cleaned_fies, components, aggregate_column, negative_components=loss_components)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n",
    "# If there are mismatches, display them\n",
    "if not mismatched_rows.empty:\n",
    "    print(\"Mismatched rows:\")\n",
    "    print(mismatched_rows[[aggregate_column, 'TEMP_SUM'] + components])\n",
    "else:\n",
    "    Wages_components = components\n",
    "\n",
    "Wages_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible component columns\n",
    "components = [\n",
    "    'NET_CFG', 'NET_LPR', 'NET_FISH', 'NET_FOR', \n",
    "    'NET_RET', 'NET_MFG', 'NET_TRANS', 'NET_NEC_A8', \n",
    "    'NET_NEC_A9', 'NET_NEC_A10', 'LOSSES'\n",
    "]\n",
    "\n",
    "loss_components = []\n",
    "aggregate_column = 'EAINC'\n",
    "\n",
    "# Call the function verify the aggregated column\n",
    "mismatched_rows, result = check_aggregation(cleaned_fies, components, aggregate_column, negative_components=loss_components)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n",
    "# If there are mismatches, display them\n",
    "if not mismatched_rows.empty:\n",
    "    print(\"Mismatched rows:\")\n",
    "    print(mismatched_rows[[aggregate_column, 'TEMP_SUM'] + components])\n",
    "else:\n",
    "    EAINC_components = components\n",
    "\n",
    "EAINC_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible component columns\n",
    "components = [\n",
    "    'WAGES', 'NETSHARE', 'CASH_ABROAD', 'CASH_DOMESTIC', 'RENTALS_REC', \n",
    "    'INTEREST', 'PENSION', 'DIVIDENDS', 'OTHER_SOURCE', 'NET_RECEIPT', 'REGFT',\n",
    "    'IMPUTED_RENT', 'EAINC'\n",
    "]\n",
    "\n",
    "loss_components = []\n",
    "aggregate_column = 'TOINC'\n",
    "\n",
    "# Call the function verify the aggregated column\n",
    "mismatched_rows, result = check_aggregation(cleaned_fies, components, aggregate_column, negative_components=loss_components)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n",
    "# If there are mismatches, display them\n",
    "if not mismatched_rows.empty:\n",
    "    print(\"Mismatched rows:\")\n",
    "    print(mismatched_rows[[aggregate_column, 'TEMP_SUM']])\n",
    "else:\n",
    "    TOINC_components = components\n",
    "\n",
    "TOINC_components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible component columns\n",
    "components = [\n",
    "    'BREAD', 'MEAT', 'FISH', 'MILK', 'OIL', 'FRUIT', 'VEG', 'SUGAR', 'FOOD_NEC',\n",
    "    'FRUIT_VEG', 'COFFEE', 'TEA', 'COCOA', 'WATER', 'SOFTDRINKS', 'OTHER_NON_ALCOHOL'\n",
    "]\n",
    "\n",
    "loss_components = []\n",
    "aggregate_column = 'FOOD_HOME'\n",
    "\n",
    "# Call the function verify the aggregated column\n",
    "mismatched_rows, result = check_aggregation(cleaned_fies, components, aggregate_column, negative_components=loss_components)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n",
    "# If there are mismatches, display them\n",
    "if not mismatched_rows.empty:\n",
    "    print(\"Mismatched rows:\")\n",
    "    print(mismatched_rows[[aggregate_column, 'TEMP_SUM']])\n",
    "else:\n",
    "    FOOD_HOME_components = components\n",
    "\n",
    "FOOD_HOME_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible component columns\n",
    "components = [\n",
    "    'FOOD_HOME', 'FOOD_OUTSIDE'\n",
    "]\n",
    "\n",
    "aggregate_column = 'FOOD'\n",
    "loss_components = []\n",
    "\n",
    "# Call the function verify the aggregated column\n",
    "mismatched_rows, result = check_aggregation(cleaned_fies, components, aggregate_column, negative_components=loss_components)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n",
    "# If there are mismatches, display them\n",
    "if not mismatched_rows.empty:\n",
    "    print(\"Mismatched rows:\")\n",
    "    print(mismatched_rows[[aggregate_column, 'TEMP_SUM']])\n",
    "else:\n",
    "    FOOD_components = components\n",
    "\n",
    "FOOD_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible component columns\n",
    "components = [\n",
    "    'ALCOHOL', 'TOBACCO', 'OTHER_VEG', 'SERVICES_PRIMARY_GOODS', \n",
    "    'ALCOHOL_PROCDUCTION_SERVICES', 'CLOTH', 'HOUSING_WATER', \n",
    "    'FURNISHING', 'HEALTH','TRANSPORT',  'COMMUNICATION', 'RECREATION',\n",
    "    'EDUCATION','INSURANCE','MISCELLANEOUS', 'DURABLE','OCCASION',\n",
    "    'OTHER_EXPENDITURE', 'FOOD_ACCOM_SRVC',\n",
    "]\n",
    "\n",
    "aggregate_column = 'NFOOD'\n",
    "loss_components = []\n",
    "\n",
    "# Call the function verify the aggregated column\n",
    "mismatched_rows, result = check_aggregation(cleaned_fies, components, aggregate_column, negative_components=loss_components)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n",
    "# If there are mismatches, display them\n",
    "if not mismatched_rows.empty:\n",
    "    print(\"Mismatched rows:\")\n",
    "    print(mismatched_rows[[aggregate_column, 'TEMP_SUM']])\n",
    "else:\n",
    "    NFOOD_components = components\n",
    "\n",
    "NFOOD_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible component columns\n",
    "components = [\n",
    "    'FOOD', 'NFOOD'\n",
    "]\n",
    "\n",
    "aggregate_column = 'TOTEX'\n",
    "loss_components = []\n",
    "\n",
    "# Call the function verify the aggregated column\n",
    "mismatched_rows, result = check_aggregation(cleaned_fies, components, aggregate_column, negative_components=loss_components)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n",
    "# If there are mismatches, display them\n",
    "if not mismatched_rows.empty:\n",
    "    print(\"Mismatched rows:\")\n",
    "    print(mismatched_rows[[aggregate_column, 'TEMP_SUM']])\n",
    "else:\n",
    "    TOTEX_components = components\n",
    "\n",
    "TOTEX_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible component columns\n",
    "components = [\n",
    "    'TOTEX', 'OTHER_DISBURSEMENT'\n",
    "]\n",
    "\n",
    "aggregate_column = 'TOTDIS'\n",
    "loss_components = []\n",
    "\n",
    "# Call the function verify the aggregated column\n",
    "mismatched_rows, result = check_aggregation(cleaned_fies, components, aggregate_column, negative_components=loss_components)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n",
    "# If there are mismatches, display them\n",
    "if not mismatched_rows.empty:\n",
    "    print(\"Mismatched rows:\")\n",
    "    print(mismatched_rows[[aggregate_column, 'TEMP_SUM']])\n",
    "else:\n",
    "    TOTDIS_components = components\n",
    "\n",
    "TOTDIS_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible component columns\n",
    "components = [\n",
    "    'TOINC', 'OTHREC'\n",
    "]\n",
    "\n",
    "aggregate_column = 'TOREC'\n",
    "loss_components = []\n",
    "\n",
    "# Call the function verify the aggregated column\n",
    "mismatched_rows, result = check_aggregation(cleaned_fies, components, aggregate_column, negative_components=loss_components)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n",
    "\n",
    "# If there are mismatches, display them\n",
    "if not mismatched_rows.empty:\n",
    "    print(\"Mismatched rows:\")\n",
    "    print(mismatched_rows[[aggregate_column, 'TEMP_SUM']])\n",
    "else:\n",
    "    TOREC_components = components\n",
    "\n",
    "TOREC_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all column names of the cleaned_fies DataFrame\n",
    "cleaned_fies_columns = cleaned_fies.columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "print(\"Complete columns in cleaned_fies:\", cleaned_fies_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the component lists for each aggregated column\n",
    "print(\"WAGES components:\", Wages_components)\n",
    "print(\"EAINC components:\", EAINC_components)\n",
    "print(\"TOINC components:\", TOINC_components)\n",
    "print(\"FOOD_HOME components:\", FOOD_HOME_components)\n",
    "print(\"FOOD components:\", FOOD_components)\n",
    "print(\"NFOOD components:\", NFOOD_components)\n",
    "print(\"TOTEX components:\", TOTEX_components)\n",
    "print(\"TOTDIS components:\", TOTDIS_components)\n",
    "print(\"TOREC components:\", TOREC_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract names and parents from hierarchical data\n",
    "def extract_hierarchy(data, parent=\"Root\"):\n",
    "    names = []\n",
    "    parents = []\n",
    "    for key, value in data.items():\n",
    "        names.append(key)\n",
    "        parents.append(parent)\n",
    "        if isinstance(value, dict):\n",
    "            child_names, child_parents = extract_hierarchy(value, key)\n",
    "            names.extend(child_names)\n",
    "            parents.extend(child_parents)\n",
    "    return names, parents\n",
    "\n",
    "# Extract names and parents from the dataset hierarchy\n",
    "names, parents = extract_hierarchy({\n",
    "    \"W_REGN\": None,\n",
    "    \"W_PROV\": None,\n",
    "    \"SEQ_NO\": None,\n",
    "    \"RPROV\": None,\n",
    "    \"FSIZE\": None,\n",
    "    \"TOREC\": {\n",
    "        \"TOINC\": {\n",
    "            \"WAGES\": {\n",
    "                \"REG_SAL\": None,\n",
    "                \"SEASON_SAL\": None\n",
    "            },\n",
    "            \"NETSHARE\": None,\n",
    "            \"CASH_ABROAD\": None,\n",
    "            \"CASH_DOMESTIC\": None,\n",
    "            \"RENTALS_REC\": None,\n",
    "            \"INTEREST\": None,\n",
    "            \"PENSION\": None,\n",
    "            \"DIVIDENDS\": None,\n",
    "            \"OTHER_SOURCE\": None,\n",
    "            \"NET_RECEIPT\": None,\n",
    "            \"REGFT\": None,\n",
    "            \"IMPUTED_RENT\": None,\n",
    "            \"EAINC\": {\n",
    "                \"NET_CFG\": None,\n",
    "                \"NET_LPR\": None,\n",
    "                \"NET_FISH\": None,\n",
    "                \"NET_FOR\": None,\n",
    "                \"NET_RET\": None,\n",
    "                \"NET_MFG\": None,\n",
    "                \"NET_TRANS\": None,\n",
    "                \"NET_NEC_A8\": None,\n",
    "                \"NET_NEC_A9\": None,\n",
    "                \"NET_NEC_A10\": None,\n",
    "                \"LOSSES\": None\n",
    "            }\n",
    "        },\n",
    "        \"OTHREC\": None\n",
    "    },\n",
    "    \"TOTDIS\": {\n",
    "        \"TOTEX\": {\n",
    "            \"FOOD\": {\n",
    "                \"FOOD_HOME\": {\n",
    "                    \"BREAD\": None,\n",
    "                    \"MEAT\": None,\n",
    "                    \"FISH\": None,\n",
    "                    \"MILK\": None,\n",
    "                    \"OIL\": None,\n",
    "                    \"FRUIT\": None,\n",
    "                    \"VEG\": None,\n",
    "                    \"SUGAR\": None,\n",
    "                    \"FOOD_NEC\": None,\n",
    "                    \"FRUIT_VEG\": None,\n",
    "                    \"COFFEE\": None,\n",
    "                    \"TEA\": None,\n",
    "                    \"COCOA\": None,\n",
    "                    \"WATER\": None,\n",
    "                    \"SOFTDRINKS\": None,\n",
    "                    \"OTHER_NON_ALCOHOL\": None\n",
    "                },\n",
    "                \"FOOD_OUTSIDE\": None\n",
    "            },\n",
    "            \"NFOOD\": {\n",
    "                \"ALCOHOL\": None,\n",
    "                \"TOBACCO\": None,\n",
    "                \"OTHER_VEG\": None,\n",
    "                \"SERVICES_PRIMARY_GOODS\": None,\n",
    "                \"ALCOHOL_PROCDUCTION_SERVICES\": None,\n",
    "                \"CLOTH\": None,\n",
    "                \"HOUSING_WATER\": None,\n",
    "                \"FURNISHING\": None,\n",
    "                \"HEALTH\": None,\n",
    "                \"TRANSPORT\": None,\n",
    "                \"COMMUNICATION\": None,\n",
    "                \"RECREATION\": None,\n",
    "                \"EDUCATION\": None,\n",
    "                \"INSURANCE\": None,\n",
    "                \"MISCELLANEOUS\": None,\n",
    "                \"DURABLE\": None,\n",
    "                \"OCCASION\": None,\n",
    "                \"OTHER_EXPENDITURE\": None,\n",
    "                \"FOOD_ACCOM_SRVC\": None\n",
    "            }\n",
    "        },\n",
    "        \"OTHER_DISBURSEMENT\": None\n",
    "    },\n",
    "    \"RPSU\": None,\n",
    "    \"RFACT\": None,\n",
    "    \"MEM_RFACT\": None,\n",
    "    \"URB\": None,\n",
    "    \"PERCAPITA\": None,\n",
    "    \"NPCINC\": None,\n",
    "    \"RPCINC\": None,\n",
    "    \"PRPCINC\": None,\n",
    "    \"PPCINC\": None,\n",
    "    \"RPCINC_NIR\": None,\n",
    "    \"W_REGN_NIR\": None\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the treemap visualization\n",
    "fig = px.treemap(\n",
    "    names=names,\n",
    "    parents=parents,\n",
    "    title=\"Hierarchy of Columns in FIES Dataset\",\n",
    "    color_discrete_sequence=[\"#636EFA\", \"#EF553B\", \"#00CC96\", \"#AB63FA\"]\n",
    "\n",
    ")\n",
    "fig.update_traces(root_color=\"lightgrey\")\n",
    "fig.update_layout(\n",
    "    width=1400,  # Set the width of the figure\n",
    "    height=800,  # Set the height of the figure\n",
    "    margin=dict(t=50, l=25, r=25, b=25)  # Adjust the margins if needed\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all column names of the cleaned_fies DataFrame\n",
    "cleaned_fies_columns = cleaned_fies.columns.tolist()\n",
    "\n",
    "# Print the list of column names\n",
    "print(\"Complete columns in cleaned_fies:\", cleaned_fies_columns)\n",
    "\n",
    "# Printing the component lists for each aggregated column\n",
    "print(\"WAGES components:\", Wages_components)\n",
    "print(\"EAINC components:\", EAINC_components)\n",
    "print(\"TOINC components:\", TOINC_components)\n",
    "print(\"FOOD_HOME components:\", FOOD_HOME_components)\n",
    "print(\"FOOD components:\", FOOD_components)\n",
    "print(\"NFOOD components:\", NFOOD_components)\n",
    "print(\"TOTEX components:\", TOTEX_components)\n",
    "print(\"TOTDIS components:\", TOTDIS_components)\n",
    "print(\"TOREC components:\", TOREC_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_heatmap(dataframe, aggregated_column, components, title):\n",
    "    # Subset the dataframe\n",
    "    subset = dataframe[[aggregated_column] + components]\n",
    "    \n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = subset.corr()\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True, square=True)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grouped_bar_chart_average(dataframe, components, group_by_column, title):\n",
    "    # Calculate average values for components grouped by the specified column\n",
    "    averages = dataframe.groupby(group_by_column)[components].mean().reset_index()\n",
    "    \n",
    "    # Melt the dataframe for easier plotting\n",
    "    melted = averages.melt(id_vars=[group_by_column], \n",
    "                           value_vars=components, \n",
    "                           var_name='Component', \n",
    "                           value_name='Average Value')\n",
    "    \n",
    "    # Plot the grouped bar chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=melted, x=group_by_column, y='Average Value', hue='Component', palette='viridis')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Average Value')\n",
    "    plt.xlabel(group_by_column)\n",
    "    plt.legend(title='Component')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregated column and its components\n",
    "aggregated_col = 'WAGES'\n",
    "components_list = Wages_components\n",
    "title = f'Average Values of Wages by region'\n",
    "\n",
    "# Call the function\n",
    "plot_grouped_bar_chart_average(cleaned_fies, components_list, group_by_column='W_REGN', title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregated column and its components\n",
    "aggregated_col = 'EAINC'\n",
    "components_list = EAINC_components\n",
    "title = f'Heatmap Correlation: {aggregated_col} and Its Components'\n",
    "\n",
    "# Call the function\n",
    "plot_correlation_heatmap(cleaned_fies, aggregated_col, components_list, title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregated column and its components\n",
    "aggregated_col = 'TOINC'\n",
    "components_list = TOINC_components\n",
    "title = f'Heatmap Correlation: {aggregated_col} and Its Components'\n",
    "\n",
    "# Call the function\n",
    "plot_correlation_heatmap(cleaned_fies, aggregated_col, components_list, title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregated column and its components\n",
    "aggregated_col = 'FOOD_HOME'\n",
    "components_list = FOOD_HOME_components\n",
    "title = f'Heatmap Correlation: {aggregated_col} and Its Components'\n",
    "\n",
    "# Call the function\n",
    "plot_correlation_heatmap(cleaned_fies, aggregated_col, components_list, title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregated column and its components\n",
    "aggregated_col = 'NFOOD'\n",
    "components_list = NFOOD_components\n",
    "title = f'Heatmap Correlation: {aggregated_col} and Its Components'\n",
    "\n",
    "# Call the function\n",
    "plot_correlation_heatmap(cleaned_fies, aggregated_col, components_list, title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregated column and its components\n",
    "aggregated_col = 'FOOD'\n",
    "components_list = FOOD_components\n",
    "title = f'Average Values of Food Expenses by region'\n",
    "\n",
    "# Call the function\n",
    "plot_grouped_bar_chart_average(cleaned_fies, components_list, group_by_column='W_REGN', title=title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the aggregated column and its components\n",
    "aggregated_col = 'TOTEX'\n",
    "components_list = TOTEX_components\n",
    "title = f'Average Values of Total Expenses by region'\n",
    "\n",
    "# Call the function\n",
    "plot_grouped_bar_chart_average(cleaned_fies, components_list, group_by_column='W_REGN', title=title)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
